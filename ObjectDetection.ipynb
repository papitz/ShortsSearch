{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b528343-6cd1-4c8a-9ae4-69d2911bb5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (1.26.2)\n",
      "Requirement already satisfied: ultralytics in ./venv/lib/python3.11/site-packages (8.0.211)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./venv/lib/python3.11/site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./venv/lib/python3.11/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./venv/lib/python3.11/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (0.16.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./venv/lib/python3.11/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./venv/lib/python3.11/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in ./venv/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in ./venv/lib/python3.11/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.3.101)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install opencv-python numpy ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e48b57db-38f7-4a3e-9db6-8d7601c0b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81298870-1587-4b5a-99b5-e08210591176",
   "metadata": {},
   "source": [
    "## Function to extract object names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f799ea3-fae8-4137-8aa1-d9e9632f62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_objects(result):\n",
    "    objectIndices = result[0].probs.top5\n",
    "    objects = []\n",
    "    for index in objectIndices:\n",
    "        objects.append(result[0].names[index])\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bd9de-d565-47c3-b0a6-1c749460aa27",
   "metadata": {},
   "source": [
    "## Function to get objects from single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31cefa9e-aafa-455b-8ed4-86466e57eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objects_from_frame(model, frame):\n",
    "    result = model.predict(source=frame)\n",
    "    return get_list_of_objects(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c108d38-14e2-4b59-8905-dec021e25214",
   "metadata": {},
   "source": [
    "## Use a pretrained YOLO model to predict objects in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eddb548-775b-47de-a7ba-f5535201548f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x-cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e92c4526-0da7-4780-9c61-075c3a80f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /home/paul/Uni/SEP/ShortSearch/bus.jpg: 224x224 minibus 0.95, amphibian 0.02, trolleybus 0.01, recreational_vehicle 0.01, passenger_car 0.00, 96.5ms\n",
      "Speed: 1.0ms preprocess, 96.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(source=\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23995a25-753b-4e58-8be5-3878b8fe8e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minibus', 'amphibian', 'trolleybus', 'recreational_vehicle', 'passenger_car']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getListOfObjects(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48d583c7-cdcc-44c3-897b-10c64faa5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e0b68-7cd0-49ff-9076-0f9ab3d18a65",
   "metadata": {},
   "source": [
    "## Get all frames from a video and find objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56a994eb-70cf-4fc7-b4ea-55c25ddcf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects_in_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Extract every fifth frame\n",
    "    frame_interval = 5\n",
    "    detected_objects = set()\n",
    "    for frame_number in range(0, frame_count, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(f\"Error reading frame {frame_number}\")\n",
    "            break\n",
    "\n",
    "        # Call the provided function with the extracted frame\n",
    "        for detected_object in get_objects_from_frame(model, frame):   \n",
    "            detected_objects.add(detected_object)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(detected_objects)\n",
    "    return detected_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f2c68-49e1-4002-8387-2c72ac9854d5",
   "metadata": {},
   "source": [
    "## Run video classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df120d9b-9468-463b-a9ae-9441c3e7d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 desk 0.42, folding_chair 0.33, dining_table 0.07, studio_couch 0.02, sewing_machine 0.01, 96.7ms\n",
      "Speed: 1.0ms preprocess, 96.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 desk 0.52, folding_chair 0.30, dining_table 0.09, sewing_machine 0.01, studio_couch 0.01, 84.1ms\n",
      "Speed: 4.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 desk 0.24, folding_chair 0.18, dining_table 0.14, table_lamp 0.05, studio_couch 0.04, 89.7ms\n",
      "Speed: 2.3ms preprocess, 89.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 folding_chair 0.34, dining_table 0.10, desk 0.08, stove 0.03, paper_towel 0.03, 86.4ms\n",
      "Speed: 2.8ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 dining_table 0.51, desk 0.13, folding_chair 0.06, grand_piano 0.03, upright 0.02, 109.1ms\n",
      "Speed: 30.6ms preprocess, 109.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 desk 0.25, studio_couch 0.14, stove 0.07, radio 0.06, modem 0.05, 84.6ms\n",
      "Speed: 1.0ms preprocess, 84.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 shoe_shop 0.09, desk 0.06, violin 0.05, refrigerator 0.04, studio_couch 0.04, 87.4ms\n",
      "Speed: 1.5ms preprocess, 87.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 desk 0.13, medicine_chest 0.06, beaker 0.05, paper_towel 0.04, entertainment_center 0.04, 82.5ms\n",
      "Speed: 1.7ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.07, refrigerator 0.06, pop_bottle 0.06, espresso_maker 0.05, joystick 0.05, 85.5ms\n",
      "Speed: 0.9ms preprocess, 85.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.18, desk 0.06, medicine_chest 0.05, pop_bottle 0.05, joystick 0.05, 91.4ms\n",
      "Speed: 1.5ms preprocess, 91.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.16, refrigerator 0.10, soap_dispenser 0.08, espresso_maker 0.05, water_jug 0.04, 117.8ms\n",
      "Speed: 34.9ms preprocess, 117.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.16, pop_bottle 0.10, medicine_chest 0.10, soap_dispenser 0.05, carpenter's_kit 0.04, 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.22, joystick 0.06, refrigerator 0.06, medicine_chest 0.05, pop_bottle 0.05, 81.6ms\n",
      "Speed: 1.3ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.12, carpenter's_kit 0.10, pop_bottle 0.07, candle 0.06, pencil_sharpener 0.06, 81.9ms\n",
      "Speed: 1.2ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.35, soap_dispenser 0.10, joystick 0.06, mortar 0.06, pop_bottle 0.05, 93.7ms\n",
      "Speed: 1.0ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.32, pop_bottle 0.23, beer_bottle 0.07, carpenter's_kit 0.04, joystick 0.03, 88.7ms\n",
      "Speed: 1.1ms preprocess, 88.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 pop_bottle 0.24, beaker 0.23, beer_bottle 0.11, water_bottle 0.03, wine_bottle 0.03, 100.5ms\n",
      "Speed: 1.3ms preprocess, 100.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.30, pop_bottle 0.16, nipple 0.05, mortar 0.04, medicine_chest 0.04, 98.9ms\n",
      "Speed: 1.5ms preprocess, 98.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 beaker 0.29, nipple 0.18, mortar 0.04, pop_bottle 0.04, water_jug 0.03, 104.4ms\n",
      "Speed: 1.3ms preprocess, 104.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 coffee_mug 0.25, beaker 0.12, cup 0.08, eggnog 0.07, tray 0.06, 81.6ms\n",
      "Speed: 2.8ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 coffee_mug 0.34, cup 0.19, tray 0.07, candle 0.06, measuring_cup 0.03, 122.8ms\n",
      "Speed: 35.4ms preprocess, 122.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 potter's_wheel 0.18, water_jug 0.13, beaker 0.12, cup 0.08, coffee_mug 0.05, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 cup 0.29, coffee_mug 0.15, water_jug 0.14, beaker 0.06, goblet 0.03, 82.4ms\n",
      "Speed: 1.5ms preprocess, 82.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 cup 0.29, coffee_mug 0.21, potter's_wheel 0.10, water_jug 0.06, beaker 0.06, 91.5ms\n",
      "Speed: 1.5ms preprocess, 91.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 coffee_mug 0.19, potter's_wheel 0.15, beaker 0.10, cup 0.08, water_jug 0.04, 76.8ms\n",
      "Speed: 1.0ms preprocess, 76.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 cup 0.29, coffee_mug 0.25, potter's_wheel 0.09, water_jug 0.05, measuring_cup 0.04, 75.0ms\n",
      "Speed: 1.0ms preprocess, 75.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "\n",
      "0: 224x224 coffee_mug 0.33, cup 0.08, tray 0.05, potter's_wheel 0.05, beaker 0.03, 76.6ms\n",
      "Speed: 0.8ms preprocess, 76.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'espresso_maker', 'stove', 'radio', 'refrigerator', 'upright', 'modem', 'coffee_mug', \"potter's_wheel\", 'entertainment_center', 'measuring_cup', 'folding_chair', 'sewing_machine', 'joystick', 'mortar', 'shoe_shop', 'candle', 'table_lamp', 'paper_towel', 'wine_bottle', 'nipple', 'studio_couch', 'water_jug', \"carpenter's_kit\", 'violin', 'grand_piano', 'beer_bottle', 'eggnog', 'cup', 'medicine_chest', 'soap_dispenser', 'desk', 'pop_bottle', 'tray', 'pencil_sharpener', 'goblet', 'beaker', 'water_bottle', 'dining_table'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beaker',\n",
       " 'beer_bottle',\n",
       " 'candle',\n",
       " \"carpenter's_kit\",\n",
       " 'coffee_mug',\n",
       " 'cup',\n",
       " 'desk',\n",
       " 'dining_table',\n",
       " 'eggnog',\n",
       " 'entertainment_center',\n",
       " 'espresso_maker',\n",
       " 'folding_chair',\n",
       " 'goblet',\n",
       " 'grand_piano',\n",
       " 'joystick',\n",
       " 'measuring_cup',\n",
       " 'medicine_chest',\n",
       " 'modem',\n",
       " 'mortar',\n",
       " 'nipple',\n",
       " 'paper_towel',\n",
       " 'pencil_sharpener',\n",
       " 'pop_bottle',\n",
       " \"potter's_wheel\",\n",
       " 'radio',\n",
       " 'refrigerator',\n",
       " 'sewing_machine',\n",
       " 'shoe_shop',\n",
       " 'soap_dispenser',\n",
       " 'stove',\n",
       " 'studio_couch',\n",
       " 'table_lamp',\n",
       " 'tray',\n",
       " 'upright',\n",
       " 'violin',\n",
       " 'water_bottle',\n",
       " 'water_jug',\n",
       " 'wine_bottle'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_objects_in_video(\"./test.mp4\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45263c2-03a7-4eb3-bbcc-9b650ca5e73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
